{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c505785",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "os.chdir(\"..\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d213f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path_mapping(data):\n",
    "    path_dict = {}\n",
    "    for p in data:\n",
    "        path_dict[p[\"path_id\"]] = p\n",
    "    return path_dict\n",
    "\n",
    "\n",
    "def load_nav_graphs(scans):\n",
    "    ''' Load connectivity graph for each scan '''\n",
    "\n",
    "    def distance(pose1, pose2):\n",
    "        ''' Euclidean distance between two graph poses '''\n",
    "        return ((pose1['pose'][3]-pose2['pose'][3])**2\\\n",
    "          + (pose1['pose'][7]-pose2['pose'][7])**2\\\n",
    "          + (pose1['pose'][11]-pose2['pose'][11])**2)**0.5\n",
    "\n",
    "    graphs = {}\n",
    "    for scan in scans:\n",
    "        with open('connectivity/%s_connectivity.json' % scan) as f:\n",
    "            G = nx.Graph()\n",
    "            positions = {}\n",
    "            data = json.load(f)\n",
    "            for i,item in enumerate(data):\n",
    "                if item['included']:\n",
    "                    for j,conn in enumerate(item['unobstructed']):\n",
    "                        if conn and data[j]['included']:\n",
    "                            positions[item['image_id']] = np.array([item['pose'][3],\n",
    "                                    item['pose'][7], item['pose'][11]]);\n",
    "                            assert data[j]['unobstructed'][i], 'Graph should be undirected'\n",
    "                            G.add_edge(item['image_id'],data[j]['image_id'],weight=distance(item,data[j]))\n",
    "            nx.set_node_attributes(G, values=positions, name='position')\n",
    "            graphs[scan] = G\n",
    "    return graphs\n",
    "\n",
    "def fix_path(node_path):\n",
    "    \"\"\" Fixes duplicate nodes from paths given by low-level action space\n",
    "    \"\"\"\n",
    "    fixed_path = []\n",
    "    current = None\n",
    "    for node in node_path:\n",
    "        if node != current:\n",
    "            fixed_path.append(node)\n",
    "            \n",
    "        current = node\n",
    "        \n",
    "    return fixed_path\n",
    "        \n",
    "def get_path_length(graph, node_path):\n",
    "    \"\"\" Returns the path length in meters for a given node path\n",
    "    \"\"\"\n",
    "    path_length = 0\n",
    "    \n",
    "    for i in range(len(node_path)-1):\n",
    "        u, v = node_path[i], node_path[i+1]\n",
    "        path_length += graph[u][v][\"weight\"]\n",
    "        \n",
    "    return path_length\n",
    "\n",
    "def get_osr(graph, node_path, gold_node, threshold=3.0):\n",
    "    \"\"\" A function which returns oracle sucess for a single path\n",
    "    \"\"\"\n",
    "    osr = 0\n",
    "    for node in node_path:\n",
    "        shortest_path = nx.shortest_path(graph, source=node, target=gold_node, weight=\"weight\")\n",
    "        navigation_error = sum(graph[u][v][\"weight\"] for u, v in zip(shortest_path[:-1], shortest_path[1:]))\n",
    "        \n",
    "        if navigation_error < threshold:\n",
    "            osr = 1\n",
    "            break\n",
    "            \n",
    "    return osr\n",
    "\n",
    "def get_ne(graph, source, target):\n",
    "    shortest_path = nx.shortest_path(graph, source=source, target=target, weight=\"weight\")\n",
    "    \n",
    "    return sum(graph[u][v][\"weight\"] for u, v in zip(shortest_path[:-1], shortest_path[1:]))\n",
    "    \n",
    "\n",
    "def calculate_pc(reference, predicted, graph, threshold=3.0):\n",
    "    pc = 0\n",
    "    \n",
    "    for ref in reference:\n",
    "        min_distance = 1000\n",
    "        for pred in predicted:\n",
    "            shortest_path = nx.shortest_path(graph, source=ref, target=pred, weight=\"weight\")\n",
    "            distance = sum(graph[u][v][\"weight\"] for u, v in zip(shortest_path[:-1], shortest_path[1:]))\n",
    "            \n",
    "            min_distance = min(distance, min_distance)\n",
    "            \n",
    "        \n",
    "        pc += math.exp(-(min_distance/threshold))\n",
    "        \n",
    "    return pc/len(reference)\n",
    "\n",
    "def calculate_epl(reference, predicted, pc, graph):\n",
    "    epl = pc * reference[\"distance\"]\n",
    "    return epl\n",
    "\n",
    "def calculate_ls(reference, predicted, pc, graph):\n",
    "    epl = calculate_epl(reference, predicted, pc, graph)\n",
    "    pl = get_path_length(graph, predicted)\n",
    "    ls = epl/(epl+ abs(epl-pl))\n",
    "    return ls\n",
    "    \n",
    "\n",
    "def get_results(r2r_data, data, actions, instruction_index, threshold=3.0):\n",
    "    print(len(data))\n",
    "    r2r_mapping = get_path_mapping(r2r_data)\n",
    "    scans = set([p[\"scan\"] for p in r2r_mapping.values()])\n",
    "\n",
    "    G = load_nav_graphs(scans)\n",
    "    \n",
    "    sr = 0\n",
    "    ne = 0\n",
    "    pl = 0\n",
    "    osr = 0\n",
    "    spl = 0\n",
    "    cls = 0\n",
    "    \n",
    "    stats = []\n",
    "    \n",
    "    for path_id, path in data.items():\n",
    "        path_data = r2r_mapping[int(path_id)]\n",
    "        gold_node = path_data[\"path\"][-1]\n",
    "        tmp_g = G[path_data[\"scan\"]]\n",
    "        \n",
    "        old_path = path\n",
    "        path = fix_path(path)\n",
    "        \n",
    "        current_path_length = get_path_length(tmp_g, path)\n",
    "        current_navigation_error = get_ne(tmp_g, path[-1], gold_node)\n",
    "        pc = calculate_pc(path_data[\"path\"], path, tmp_g, threshold=threshold)\n",
    "        \n",
    "        # metrics\n",
    "        cls += pc * calculate_ls(path_data, path, pc, tmp_g)\n",
    "        pl += get_path_length(tmp_g, path)\n",
    "        ne += current_navigation_error  \n",
    "        osr += get_osr(tmp_g, path, gold_node, threshold=threshold)\n",
    "        \n",
    "        success_indicator = 0\n",
    "        # navigation error less than 3 = success\n",
    "        if current_navigation_error < threshold and len(old_path) < 32 and actions[str(path_id)][-1] == \"Stop\":\n",
    "            sr += 1\n",
    "            success_indicator = 1\n",
    "                \n",
    "        spl += (success_indicator*(path_data[\"distance\"]/max(path_data[\"distance\"], current_path_length)))\n",
    "        \n",
    "        stats.append({\n",
    "            \"path_id\" : path_id, \n",
    "            \"success\" : True if success_indicator == 1 else False,\n",
    "            \"instruction\" : path_data[\"instructions\"][instruction_index],\n",
    "            \"path_length\" : current_path_length\n",
    "        })\n",
    "        \n",
    "    success_rate = sr/len(data)  \n",
    "    navigation_error = ne/len(data)\n",
    "    average_path_length = pl/len(data)\n",
    "    oracle_success_rate = osr/len(data)\n",
    "    spl = spl/len(data)\n",
    "    cls = cls/len(data)\n",
    "    \n",
    "    return success_rate, navigation_error, average_path_length, oracle_success_rate, spl, cls, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb67cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"qwen2_5\"\n",
    "split = \"seen\"\n",
    "action_space = \"non_panoramic\"\n",
    "threshold = 3.0\n",
    "\n",
    "base_path = f\"./model_paths/alternative-setups/no-adjust/{model}_{action_space}_no_adjust_{split}_inst_0.json\"\n",
    "action_path = f\"./model_paths/alternative-setups/no-adjust/actions_{model}_{action_space}_no_adjust_{split}_inst_0.json\"\n",
    "\n",
    "base_path = f\"./model_paths/full-data/low-level/{model}_{action_space}_{split}_inst_0.json\"\n",
    "action_path = f\"./model_paths/full-data/low-level/actions_{model}_{action_space}_{split}_inst_0.json\"\n",
    "\n",
    "#base_path = f\"./model_paths/alternative-setups/82-vfov/{model}_{action_space}_82-vfov_{split}_inst_0.json\"\n",
    "#action_path = f\"./model_paths/alternative-setups/82-vfov/actions_{model}_{action_space}_82-vfov_{split}_inst_0.json\"\n",
    "\n",
    "#print(action_path)\n",
    "#print(\"actions_qwen2_5_non-panoramic_no_adjust_unseen_inst_2.json\")\n",
    "# Load R2R data\n",
    "with open(f\"tasks/R2R/data/R2R_val_{split}.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    r2r_data = json.load(file)\n",
    "    \n",
    "\n",
    "stats = []\n",
    "\n",
    "with open(base_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "with open(action_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    action_data = json.load(file)\n",
    "        \n",
    "results = get_results(r2r_data, data, action_data, 0, threshold)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3afd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"path_length: {round(results[2], 2)}\")\n",
    "print(f\"navigation error: {round(results[1], 2)}\")\n",
    "print(f\"oracle SR: {round(results[3], 2)}\")\n",
    "print(f\"Succeses rate: {round(results[0], 2)}\")\n",
    "print(f\"SPL: {round(results[4], 2)}\")\n",
    "print(f\"cls: {round(results[5], 2)}\")\n",
    "\n",
    "#print(r2r_data[503])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29587cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Modified version that stores the full metrics and calculates stds\n",
    "def evaluate_full_metrics():\n",
    "    models = [\"qwen2\", \"qwen2_5\"]\n",
    "    splits = [\"seen\", \"unseen\"]\n",
    "    action_spaces = [\"low-level\", \"panoramic\"]\n",
    "    data_types = [\"half-data\"]\n",
    "    threshold = 3.0\n",
    "\n",
    "    full_results = {space: [] for space in action_spaces}\n",
    "    std_results = {space: [] for space in action_spaces}\n",
    "    length_results = {space: [] for space in action_spaces}\n",
    "    \n",
    "    for d in data_types:\n",
    "        for action_space in action_spaces:\n",
    "            other_name = \"non_panoramic\" if action_space == \"low-level\" else \"panoramic\"\n",
    "            if d == \"full-data\":\n",
    "                other_name = \"non-panoramic_full\" if action_space == \"low-level\" else \"panoramic_full\"\n",
    "            for split in splits:\n",
    "                for model in models:\n",
    "                    print(f\"Evaluating: {model} | {action_space} | {split}\")\n",
    "\n",
    "                    base_path = f\"./model_paths/{d}/{action_space}/{model}_{other_name}_{split}_inst\"\n",
    "                    action_path = f\"./model_paths/{d}/{action_space}/actions_{model}_{other_name}_{split}_inst\"\n",
    "                    r2r_file = f\"./tasks/R2R/data/R2R_val_{split}.json\"\n",
    "\n",
    "                    with open(r2r_file, \"r\", encoding=\"utf-8\") as file:\n",
    "                        r2r_data = json.load(file)\n",
    "\n",
    "                    metrics_runs = []\n",
    "                    stats = []\n",
    "                    for i in range(3):\n",
    "                        with open(f\"{base_path}_{i}.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "                            data = json.load(file)\n",
    "\n",
    "                        with open(f\"{action_path}_{i}.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "                            action_data = json.load(file)\n",
    "\n",
    "                        sr, ne, pl, osr, spl, cls, run_stats = get_results(r2r_data, data, action_data, i, threshold)\n",
    "                        metrics_runs.append([pl, ne, osr, sr, spl, cls])\n",
    "                        stats.extend(run_stats)\n",
    "\n",
    "                    # Aggregate stats\n",
    "                    success_stats = [s for s in stats if s[\"success\"]]\n",
    "                    failed_stats = [s for s in stats if not s[\"success\"]]\n",
    "                    print(f\"success stats length: {len(success_stats)}\")\n",
    "                    print(f\"failed stats length: {len(failed_stats)}\")\n",
    "                    def avg_path_and_inst(stats_list):\n",
    "                        if not stats_list:\n",
    "                            return (0, 0)\n",
    "                        avg_pl = sum(s[\"path_length\"] for s in stats_list) / len(stats_list)\n",
    "                        avg_inst = sum(len(s[\"instruction\"].split(\" \")) for s in stats_list) / len(stats_list)\n",
    "                        return avg_pl, avg_inst\n",
    "\n",
    "                    s_pl, s_inst = avg_path_and_inst(success_stats)\n",
    "                    f_pl, f_inst = avg_path_and_inst(failed_stats)\n",
    "                    model_name = \"Qwen2.5-VL\" if model == \"qwen2_5\" else \"Qwen2-VL\"\n",
    "                    length_results[action_space].append({\n",
    "                        \"Model\": model_name,\n",
    "                        \"Action Space\": action_space,\n",
    "                        \"Split\": split,\n",
    "                        \"Avg. Path Length (Success)\": round(s_pl, 2),\n",
    "                        \"Avg. Instruction Length (Success)\": round(s_inst, 2),\n",
    "                        \"Avg. Path Length (Failure)\": round(f_pl, 2),\n",
    "                        \"Avg. Instruction Length (Failure)\": round(f_inst, 2)\n",
    "                    })\n",
    "\n",
    "                    metrics_np = np.array(metrics_runs)\n",
    "                    means = metrics_np.mean(axis=0)\n",
    "                    stds = metrics_np.std(axis=0)\n",
    "\n",
    "                    full_results[action_space].append({\n",
    "                        \"Split\": split,\n",
    "                        \"Model\": model_name,\n",
    "                        \"Path Length\": round(means[0], 2),\n",
    "                        \"Navigation Error\": round(means[1], 2),\n",
    "                        \"Oracle Success Rate\": round(means[2], 2),\n",
    "                        \"Success Rate\": round(means[3], 2),\n",
    "                        \"Success-Weighted by Path Length\": round(means[4], 2),\n",
    "                        \"Coverage Weighted by Length Score\": round(means[5], 2)\n",
    "                    })\n",
    "\n",
    "                    std_results[action_space].append({\n",
    "                        \"Split\": split,\n",
    "                        \"Model\": model_name,\n",
    "                        \"Path Length\": round(stds[0], 3),\n",
    "                        \"Navigation Error\": round(stds[1], 3),\n",
    "                        \"Oracle Success Rate\": round(stds[2], 3),\n",
    "                        \"Success Rate\": round(stds[3], 3),\n",
    "                        \"Success-Weighted by Path Length\": round(stds[4], 3),\n",
    "                        \"Coverage Weighted by Length Score\": round(stds[5], 3)\n",
    "                    })\n",
    "\n",
    "    return pd.DataFrame(full_results[\"low-level\"]), pd.DataFrame(full_results[\"panoramic\"]), pd.DataFrame(std_results[\"low-level\"]), pd.DataFrame(std_results[\"panoramic\"]), pd.DataFrame(length_results[\"panoramic\"]), pd.DataFrame(length_results[\"low-level\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec8c068",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "# Run the evaluation\n",
    "pan_results, pano_results, pan_std, pano_std, pano_length, non_length = evaluate_full_metrics()\n",
    "# Fix column order\n",
    "columns_order = [\n",
    "    \"Split\",\n",
    "    \"Model\",\n",
    "    \"Path Length\",\n",
    "    \"Navigation Error\",\n",
    "    \"Oracle Success Rate\",\n",
    "    \"Success Rate\",\n",
    "    \"Success-Weighted by Path Length\",\n",
    "    \"Coverage Weighted by Length Score\"\n",
    "]\n",
    "\n",
    "other_column_order = [\n",
    "    \"Split\",\n",
    "    \"Model\",\n",
    "    \"Avg. Path Length (Success)\",\n",
    "    \"Avg. Instruction Length (Success)\",\n",
    "    \"Avg. Path Length (Failure)\",\n",
    "    \"Avg. Instruction Length (Failure)\"\n",
    "]\n",
    "\n",
    "pan_results = pan_results[columns_order]\n",
    "pano_results = pano_results[columns_order]\n",
    "pan_std = pan_std[columns_order]\n",
    "pano_std = pano_std[columns_order]\n",
    "\n",
    "pano_length = pano_length[other_column_order]\n",
    "non_length = non_length[other_column_order]\n",
    "\n",
    "# Display with headers\n",
    "display(Markdown(\"### ðŸ“Š Non-Panoramic Results (Means)\"))\n",
    "display(pan_results)\n",
    "\n",
    "display(Markdown(\"### ðŸ“ˆ Non-Panoramic Results (Standard Deviations)\"))\n",
    "display(pan_std)\n",
    "\n",
    "display(Markdown(\"### ðŸ“Š Panoramic Results (Means)\"))\n",
    "display(pano_results)\n",
    "\n",
    "\n",
    "display(Markdown(\"### ðŸ“ˆ Panoramic Results (Standard Deviations)\"))\n",
    "display(pano_std)\n",
    "\n",
    "display(Markdown(\"### ðŸ“ˆ Non-panoamic Lengths\"))\n",
    "display(non_length)\n",
    "\n",
    "display(Markdown(\"### ðŸ“ˆ Panoramic Lengths\"))\n",
    "display(pano_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59869555",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set plotting style\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "mpl.rcParams['ps.fonttype'] = 42\n",
    "mpl.rcParams['figure.dpi'] = 300\n",
    "mpl.rcParams['savefig.dpi'] = 300\n",
    "\n",
    "# Label mapping for nicer axis names\n",
    "label_map = {\n",
    "    \"Avg. Path Length (Success)\": 'Path Length (Success)',\n",
    "    \"Avg. Path Length (Failure)\": 'Path Length (Failure)',\n",
    "    \"Avg. Instruction Length (Success)\": 'Instruction Length (Success)',\n",
    "    \"Avg. Instruction Length (Failure)\": 'Instruction Length (Failure)'\n",
    "}\n",
    "\n",
    "action_spaces = [\"low-level\", \"panoramic\"]\n",
    "\n",
    "for space in action_spaces:\n",
    "    if space == \"low-level\":\n",
    "        result_data = non_length\n",
    "        \n",
    "    else:\n",
    "        result_data = pano_length\n",
    "\n",
    "    # Melt DataFrame\n",
    "    pano_length_melted = result_data.melt(\n",
    "        id_vars=['Split', 'Model'],\n",
    "        value_vars=[\n",
    "            \"Avg. Path Length (Success)\", \"Avg. Path Length (Failure)\",\n",
    "            \"Avg. Instruction Length (Success)\", \"Avg. Instruction Length (Failure)\"\n",
    "        ],\n",
    "        var_name='Metric',\n",
    "        value_name='Value'\n",
    "    )\n",
    "    pano_length_melted['Metric'] = pano_length_melted['Metric'].map(label_map)\n",
    "\n",
    "    # Set theme\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    sns.set_context(\"paper\")\n",
    "    palette = sns.color_palette(\"colorblind\")\n",
    "\n",
    "    # Separate Path Lengths and Instruction Lengths\n",
    "    path_metrics = ['Path Length (Success)', 'Path Length (Failure)']\n",
    "    instruction_metrics = ['Instruction Length (Success)', 'Instruction Length (Failure)']\n",
    "\n",
    "    for split in pano_length[\"Split\"].unique():\n",
    "        print(f\"Split: {split}\")\n",
    "        subset = pano_length_melted[pano_length_melted['Split'] == split]\n",
    "\n",
    "        # --- PATH LENGTH PLOT ---\n",
    "        path_subset = subset[subset['Metric'].isin(path_metrics)]\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        ax = sns.barplot(\n",
    "            data=path_subset,   # <-- FIXED HERE\n",
    "            x=\"Model\",\n",
    "            y=\"Value\",\n",
    "            hue=\"Metric\",\n",
    "            palette=palette,\n",
    "            edgecolor=\"black\"\n",
    "        )\n",
    "        ax.set_ylim(0, path_subset[\"Value\"].max() * 1.5)\n",
    "        for container in ax.containers:\n",
    "            for bar in container:\n",
    "                height = bar.get_height()\n",
    "                ax.annotate(\n",
    "                    f\"{height:.1f}\",\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3),\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center',\n",
    "                    va='bottom',\n",
    "                    fontsize=24\n",
    "                )\n",
    "        plt.ylabel(\"Length\", fontsize=32)\n",
    "        plt.xlabel(\"\")\n",
    "        plt.xticks(fontsize=24, rotation=45)\n",
    "        plt.yticks(fontsize=18)\n",
    "        plt.legend(fontsize=18, loc=\"upper left\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"./figures/plots/{space}/{space}-path-length-{split}.pdf\", bbox_inches=\"tight\", dpi=700)\n",
    "        plt.show()\n",
    "\n",
    "        # --- INSTRUCTION LENGTH PLOT ---\n",
    "        instr_subset = subset[subset['Metric'].isin(instruction_metrics)]\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        ax = sns.barplot(\n",
    "            data=instr_subset,   # <-- FIXED HERE\n",
    "            x=\"Model\",\n",
    "            y=\"Value\",\n",
    "            hue=\"Metric\",\n",
    "            palette=palette,\n",
    "            edgecolor=\"black\"\n",
    "        )\n",
    "        ax.set_ylim(0, instr_subset[\"Value\"].max() * 1.6)\n",
    "        for container in ax.containers:\n",
    "            for bar in container:\n",
    "                height = bar.get_height()\n",
    "                ax.annotate(\n",
    "                    f\"{height:.1f}\",\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3),\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center',\n",
    "                    va='bottom',\n",
    "                    fontsize=24\n",
    "                )\n",
    "        plt.ylabel(\"Length\", fontsize=32)\n",
    "        plt.xlabel(\"\")\n",
    "        plt.xticks(fontsize=24, rotation=45)\n",
    "        plt.yticks(fontsize=18)\n",
    "        plt.legend(fontsize=18, loc=\"upper left\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"./figures/plots/{space}/{space}-instruction-length-{split}.pdf\", bbox_inches=\"tight\", dpi=700)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037a60de",
   "metadata": {},
   "source": [
    "## SR, SPL and OSR over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0347dd5b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "def get_plots_over_thresholds():\n",
    "    models = [\"qwen2\", \"qwen2_5\"]\n",
    "    action_spaces = [\"non_panoramic\", \"panoramic\"]\n",
    "    splits = [\"seen\", \"unseen\"]\n",
    "    thresholds = [5.0, 6.0, 7.0, 8.0, 9.0]\n",
    "\n",
    "    all_results = []\n",
    "\n",
    "    for action_space in action_spaces:\n",
    "        action_space_folder = \"low-level\" if action_space == \"non_panoramic\" else \"panoramic\"\n",
    "        for split in splits:\n",
    "            for model in models:\n",
    "                print(f\"Evaluating: {model} | {action_space} | {split}\")\n",
    "                \n",
    "                base_path = f\"./model_paths/half-data/{action_space_folder}/{model}_{action_space}_{split}_inst\"\n",
    "                action_path = f\"./model_paths/half-data/{action_space_folder}/actions_{model}_{action_space}_{split}_inst\"\n",
    "                r2r_file = f\"tasks/R2R/data/R2R_val_{split}.json\"\n",
    "\n",
    "                with open(r2r_file, \"r\", encoding=\"utf-8\") as file:\n",
    "                    r2r_data = json.load(file)\n",
    "\n",
    "                for t in thresholds:\n",
    "                    metrics_runs = []\n",
    "                    for i in range(3):\n",
    "                        with open(f\"{base_path}_{i}.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "                            data = json.load(file)\n",
    "\n",
    "                        with open(f\"{action_path}_{i}.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "                            action_data = json.load(file)\n",
    "\n",
    "                        sr, ne, pl, osr, spl, cls, run_stats = get_results(r2r_data, data, action_data, i, t)\n",
    "                        metrics_runs.append([ne, osr, sr, spl])\n",
    "\n",
    "                    for run_id, values in enumerate(metrics_runs):\n",
    "                        ne, osr, sr, spl = values\n",
    "                        all_results.append({\n",
    "                            \"Threshold\": t,\n",
    "                            \"Split\": split,\n",
    "                            \"Model\": model,\n",
    "                            \"Action Space\": action_space,\n",
    "                            \"Run\": run_id,\n",
    "                            \"Navigation Error\": ne,\n",
    "                            \"Oracle Success Rate\": osr,\n",
    "                            \"Success Rate\": sr,\n",
    "                            \"SPL\": spl\n",
    "                        })\n",
    "\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(all_results)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = get_plots_over_thresholds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40897f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set plotting theme\n",
    "sns.set_theme(style=\"whitegrid\", context=\"paper\")\n",
    "palette = sns.color_palette(\"colorblind\", n_colors=2)\n",
    "\n",
    "# Define combinations\n",
    "metrics = [\"Success Rate\"]\n",
    "splits = [\"seen\", \"unseen\"]\n",
    "action_spaces = [\"panoramic\", \"non_panoramic\"]\n",
    "\n",
    "# Loop over each combination\n",
    "for action_space in action_spaces:\n",
    "    for split in splits:\n",
    "        for metric in metrics:\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            \n",
    "            # Filter data for current combination\n",
    "            df_filtered = df[(df[\"Split\"] == split) & (df[\"Action Space\"] == action_space)]\n",
    "            \n",
    "            ax = sns.lineplot(\n",
    "                data=df_filtered,\n",
    "                x=\"Threshold\", y=metric,\n",
    "                hue=\"Model\",\n",
    "                style=\"Model\",  # optional, if you want different dashes\n",
    "                markers=True,\n",
    "                ci=\"sd\",  # This shows standard deviation as shaded region\n",
    "                palette=palette\n",
    "            )\n",
    "            \n",
    "            # TODO: endre pÃ¥ skriften, og legge til sÃ¥nn bedre navn pÃ¥ modellene og endre shit\n",
    "            \n",
    "            #ax.set_title(f\"{metric} vs. Threshold\\n({split}, {action_space} action space)\", fontsize=16)\n",
    "            ax.set_xlabel(\"Threshold (meters)\", fontsize=32)\n",
    "            ax.set_ylabel(metric if metric != \"SPL\" else \"Success-Weighted by Path Length\", fontsize=32)\n",
    "            ax.tick_params(labelsize=12)\n",
    "            plt.xlim(left=5, right=10)\n",
    "            plt.xticks(fontsize=18)\n",
    "            plt.yticks(fontsize=18)\n",
    "            ax.legend(title=\"Model\", fontsize=17, title_fontsize=17)\n",
    "            plt.tight_layout()\n",
    "\n",
    "            # Save plot with descriptive name\n",
    "            filename = f\"{metric.replace(' ', '_').lower()}_{split}_{action_space}_plot.pdf\"\n",
    "            plt.savefig(f\"./figures/{filename}\", bbox_inches=\"tight\", dpi=700)\n",
    "            plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef7e3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def evaluate_models():\n",
    "    models = [\"qwen2\", \"qwen2_5\"]\n",
    "    action_spaces = [\"non_panoramic\", \"panoramic\"]\n",
    "    splits = [\"seen\", \"unseen\"]\n",
    "\n",
    "    # Store all results\n",
    "    all_results = []\n",
    "\n",
    "    for action_space in action_spaces:\n",
    "        for split in splits:\n",
    "            for model in models:\n",
    "                print(f\"Evaluating: {model} | {action_space} | {split}\")\n",
    "                \n",
    "                base_path = f\"./model_paths/{model}_{action_space}_{split}_inst\"\n",
    "                action_path = f\"./model_paths/actions_{model}_{action_space}_{split}_inst\"\n",
    "                \n",
    "                r2r_file = f\"tasks/R2R/data/R2R_val_{split}.json\"\n",
    "                with open(r2r_file, \"r\", encoding=\"utf-8\") as file:\n",
    "                    r2r_data = json.load(file)\n",
    "\n",
    "                stats = []\n",
    "\n",
    "                for i in range(3):  # Assume 3 seeds/runs\n",
    "                    with open(f\"{base_path}_{i}.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "                        data = json.load(file)\n",
    "\n",
    "                    with open(f\"{action_path}_{i}.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "                        action_data = json.load(file)\n",
    "\n",
    "                    _, _, _, _, _, _, run_stats = get_results(r2r_data, data, action_data, i, threshold=3.0)\n",
    "                    stats.extend(run_stats)\n",
    "\n",
    "                # Aggregate stats\n",
    "                success_stats = [s for s in stats if s[\"success\"]]\n",
    "                failed_stats = [s for s in stats if not s[\"success\"]]\n",
    "                \n",
    "                print(f\"success stats length: {len(success_stats)}\")\n",
    "                print(f\"failed stats length: {len(failed_stats)}\")\n",
    "                \n",
    "                def avg_path_and_inst(stats_list):\n",
    "                    if not stats_list:\n",
    "                        return (0, 0)\n",
    "                    avg_pl = sum(s[\"path_length\"] for s in stats_list) / len(stats_list)\n",
    "                    avg_inst = sum(len(s[\"instruction\"].split(\" \")) for s in stats_list) / len(stats_list)\n",
    "                    return avg_pl, avg_inst\n",
    "\n",
    "                s_pl, s_inst = avg_path_and_inst(success_stats)\n",
    "                f_pl, f_inst = avg_path_and_inst(failed_stats)\n",
    "\n",
    "                all_results.append({\n",
    "                    \"Model\": model,\n",
    "                    \"Action Space\": action_space,\n",
    "                    \"Split\": split,\n",
    "                    \"Success Path Length\": round(s_pl, 2),\n",
    "                    \"Success Inst Length\": round(s_inst, 2),\n",
    "                    \"Failed Path Length\": round(f_pl, 2),\n",
    "                    \"Failed Inst Length\": round(f_inst, 2)\n",
    "                })\n",
    "\n",
    "    return all_results\n",
    "\n",
    "evaluate_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c4f805",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
