{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a979faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "os.chdir(\"..\")\n",
    "import MatterSim\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "print(os.getcwd())\n",
    "mpl.rcParams['pdf.fonttype'] = 42  # Use TrueType fonts in PDF\n",
    "mpl.rcParams['ps.fonttype'] = 42\n",
    "mpl.rcParams['figure.dpi'] = 300  # Higher DPI for better rendering\n",
    "mpl.rcParams['savefig.dpi'] = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fce4a0c",
   "metadata": {},
   "source": [
    "## Low-Level Action Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8afef0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"v3-full\"\n",
    "\n",
    "with open(\"tasks/R2R/data/R2R_train.json\", encoding=\"utf-8\") as file:\n",
    "    r2r_train = json.load(file)\n",
    "    \n",
    "with open(\"tasks/R2R/data/R2R_val_unseen.json\", encoding=\"utf-8\") as file:\n",
    "    r2r_unseen = json.load(file)\n",
    "    \n",
    "with open(\"tasks/R2R/data/R2R_val_seen.json\", encoding=\"utf-8\") as file:\n",
    "    r2r_seen = json.load(file)\n",
    "\n",
    "with open(f\"./code/dataset_{dataset}/train/train_data.json\", encoding=\"utf-8\") as file:\n",
    "    train_data = json.load(file)\n",
    "\n",
    "with open(f\"./code/dataset_{dataset}/val/val_data.json\", encoding=\"utf-8\") as file:\n",
    "    val_data = json.load(file)\n",
    "\n",
    "with open(f\"./code/dataset_{dataset}/test/test_data.json\", encoding=\"utf-8\") as file:\n",
    "    test_data = json.load(file) \n",
    "    \n",
    "# Map your splits to the original full R2R splits\n",
    "original_r2r_paths = {\n",
    "    \"Train\": len(set([item[\"path_id\"] for item in r2r_train])),\n",
    "    \"Val\": len(set([item[\"path_id\"] for item in r2r_seen])),\n",
    "    \"Test\": len(set([item[\"path_id\"] for item in r2r_unseen]))\n",
    "}\n",
    "\n",
    "def avg_steps_per_path(data):\n",
    "    path_lengths = {}\n",
    "    for item in data:\n",
    "        pid = item[\"path_id\"]\n",
    "        path_lengths[pid] = path_lengths.get(pid, 0) + 1\n",
    "    return round(sum(path_lengths.values()) / len(path_lengths), 2)\n",
    "\n",
    "# Function to compute stats\n",
    "def compute_stats(data):\n",
    "    num_samples = len(data)\n",
    "    num_paths = len(set([item[\"path_id\"] for item in data]))\n",
    "    unique_environments = len(set([item[\"scan\"] for item in data]))\n",
    "    avg_steps = avg_steps_per_path(data)\n",
    "    action_counts = Counter([\n",
    "        item[\"gold_label\"].replace(\"Stop Navigation\", \"Stop\") for item in data\n",
    "    ])\n",
    "    return num_samples, num_paths, action_counts, unique_environments, avg_steps\n",
    "\n",
    "# Compute stats\n",
    "splits = {\n",
    "    \"Train\": train_data,\n",
    "    \"Val\": val_data,\n",
    "    \"Test\": test_data\n",
    "}\n",
    "\n",
    "summary_data = []\n",
    "plot_data = []\n",
    "total_action_counts = Counter()\n",
    "\n",
    "for split_name, data in splits.items():\n",
    "    num_samples, num_paths, action_counts, unique_environments, avg_steps = compute_stats(data)\n",
    "    summary_data.append({\n",
    "        \"Split\": split_name,\n",
    "        \"Num Samples\": num_samples,\n",
    "        \"Num Paths\": num_paths,\n",
    "        \"Unique Environments\" : unique_environments,\n",
    "        \"Avg Steps Per Path\" : avg_steps\n",
    "    })\n",
    "    total = sum(action_counts.values())\n",
    "    total_action_counts.update(action_counts)\n",
    "\n",
    "    for action, count in action_counts.items():\n",
    "        plot_data.append({\n",
    "            \"Split\": split_name,\n",
    "            \"Action\": action,\n",
    "            \"Percentage\": (count / total) * 100\n",
    "        })\n",
    "\n",
    "# Order actions by total frequency\n",
    "ordered_actions = [action for action, _ in total_action_counts.most_common()]\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "plot_df[\"Action\"] = pd.Categorical(plot_df[\"Action\"], categories=ordered_actions, ordered=True)\n",
    "\n",
    "total_paths_used = sum(row[\"Num Paths\"] for row in summary_data)\n",
    "\n",
    "# Add relative path share (%) to each row\n",
    "for row in summary_data:\n",
    "    split_name = row[\"Split\"]\n",
    "    used_paths = row[\"Num Paths\"]\n",
    "    total_paths_in_r2r = original_r2r_paths[split_name]\n",
    "    row[\"Data Usage (%)\"] = round((used_paths / total_paths_in_r2r) * 100, 2)\n",
    "\n",
    "# Final tidy DataFrame\n",
    "summary_df = pd.DataFrame(summary_data)[[\n",
    "    \"Split\", \"Num Samples\", \"Num Paths\", \"Data Usage (%)\", \"Unique Environments\", \"Avg Steps Per Path\"\n",
    "]]\n",
    "\n",
    "# Print nicely\n",
    "print(\"=== Dataset Summary ===\")\n",
    "print(summary_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d5e2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")  # or\n",
    "sns.set_context(\"paper\")\n",
    "# Plot\n",
    "#palette = sns.color_palette(\"colorblind\")  # or try \"colorblind\", \"pastel\", etc.\n",
    "#palette = [\"#4D4D4D\", \"#7F7F7F\", \"#BFBFBF\"]\n",
    "palette = sns.color_palette(\"colorblind\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.barplot(\n",
    "    data=plot_df,\n",
    "    x=\"Action\",\n",
    "    y=\"Percentage\",\n",
    "    hue=\"Split\",\n",
    "    palette=palette,\n",
    "    edgecolor=\"black\"\n",
    ")\n",
    "\n",
    "for container in ax.containers:\n",
    "    for bar in container:\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(\n",
    "            f\"{height:.1f}%\",\n",
    "            xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "            xytext=(0, 3),  # 3 points above bar\n",
    "            textcoords=\"offset points\",\n",
    "            ha='center',\n",
    "            va='bottom',\n",
    "            fontsize=12\n",
    "        )\n",
    "\n",
    "plt.ylabel(\"Percentage (%)\", fontsize=18)\n",
    "plt.xlabel(\"Action\", fontsize=18)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.legend(title=\"Split\", fontsize=13, title_fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./figures/action_distribution_full.pdf\", bbox_inches=\"tight\", dpi=700)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7d9c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to compute steps per path\n",
    "def compute_path_lengths(data):\n",
    "    path_steps = defaultdict(int)\n",
    "    for item in data:\n",
    "        path_steps[item[\"path_id\"]] += 1\n",
    "    return list(path_steps.values())\n",
    "\n",
    "# Helper to compute instruction lengths\n",
    "def compute_instruction_lengths(data):\n",
    "    lengths = []\n",
    "    seen_path_ids = set()\n",
    "    for item in data:\n",
    "        if item[\"path_id\"] not in seen_path_ids:\n",
    "            seen_path_ids.add(item[\"path_id\"])\n",
    "            for inst in item[\"instructions\"]:\n",
    "                token_count = len(inst.split())\n",
    "                lengths.append(token_count)\n",
    "    return lengths\n",
    "\n",
    "# Gather data\n",
    "splits = {\n",
    "    \"Train\": train_data,\n",
    "}\n",
    "\n",
    "path_length_data = []\n",
    "instruction_length_data = []\n",
    "\n",
    "for split_name, data in splits.items():\n",
    "    # Path lengths\n",
    "    lengths = compute_path_lengths(data)\n",
    "    for length in lengths:\n",
    "        path_length_data.append({\"Split\": split_name, \"Steps per Path\": length})\n",
    "\n",
    "    # Instruction lengths\n",
    "    instr_lens = compute_instruction_lengths(data)\n",
    "    for instr_len in instr_lens:\n",
    "        instruction_length_data.append({\"Split\": split_name, \"Instruction Length\": instr_len})\n",
    "\n",
    "# Convert to DataFrames\n",
    "path_length_df = pd.DataFrame(path_length_data)\n",
    "instr_length_df = pd.DataFrame(instruction_length_data)\n",
    "\n",
    "# Plot: Histogram of steps per path\n",
    "plt.figure(figsize=(9, 5))\n",
    "sns.histplot(data=path_length_df, x=\"Steps per Path\", hue=\"Split\", bins=20, multiple=\"dodge\", palette=\"Set2\", edgecolor=\"black\")\n",
    "plt.title(\"Distribution of Steps per Path\")\n",
    "plt.xlabel(\"Number of Steps\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce1b247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set theme before plotting\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "sns.set_context(\"paper\")\n",
    "\n",
    "# Filter only the train split\n",
    "train_instr_df = instr_length_df[instr_length_df[\"Split\"] == \"Train\"]\n",
    "\n",
    "# Calculate mean and median\n",
    "mean_length = train_instr_df[\"Instruction Length\"].mean()\n",
    "median_length = train_instr_df[\"Instruction Length\"].median()\n",
    "\n",
    "print(mean_length)\n",
    "plt.figure(figsize=(9, 5))\n",
    "sns.histplot(\n",
    "    data=train_instr_df,\n",
    "    x=\"Instruction Length\",\n",
    "    bins=50,\n",
    "    color=sns.color_palette(\"colorblind\")[0],\n",
    "    edgecolor=\"black\",\n",
    "    alpha=1.0\n",
    ")\n",
    "\n",
    "# Add vertical lines\n",
    "plt.axvline(mean_length, color=palette[1], linestyle=\"--\", linewidth=1.5, label=f\"Mean: {mean_length:.1f}\")\n",
    "plt.axvline(median_length, color=palette[2], linestyle=\"--\", linewidth=1.5, label=f\"Median: {median_length:.1f}\")\n",
    "# Add legend to show labels\n",
    "plt.legend(fontsize=14)\n",
    "\n",
    "# Labels and styling\n",
    "plt.xlabel(\"Instruction Length (whitespace tokens)\", fontsize=18)\n",
    "plt.ylabel(\"Count\", fontsize=18)\n",
    "plt.xticks(range(0, train_instr_df[\"Instruction Length\"].max() + 10, 20), fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.tick_params(axis='x', which='major', length=6, width=1.2, direction='out')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./figures/histogram_instruction_length_full.pdf\", bbox_inches=\"tight\", dpi=700)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab21a40",
   "metadata": {},
   "source": [
    "## Panoramic Action Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10620c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"v5-full\"\n",
    "\n",
    "with open(\"tasks/R2R/data/R2R_train.json\", encoding=\"utf-8\") as file:\n",
    "    r2r_train = json.load(file)\n",
    "    \n",
    "with open(\"tasks/R2R/data/R2R_val_unseen.json\", encoding=\"utf-8\") as file:\n",
    "    r2r_unseen = json.load(file)\n",
    "    \n",
    "with open(\"tasks/R2R/data/R2R_val_seen.json\", encoding=\"utf-8\") as file:\n",
    "    r2r_seen = json.load(file)\n",
    "\n",
    "with open(f\"./code/dataset_{dataset}/train/train_data.json\", encoding=\"utf-8\") as file:\n",
    "    train_data = json.load(file)\n",
    "\n",
    "with open(f\"./code/dataset_{dataset}/val/val_data.json\", encoding=\"utf-8\") as file:\n",
    "    val_data = json.load(file)\n",
    "\n",
    "with open(f\"./code/dataset_{dataset}/test/test_data.json\", encoding=\"utf-8\") as file:\n",
    "    test_data = json.load(file) \n",
    "    \n",
    "    # Helper to compute steps per path\n",
    "def compute_path_lengths(data):\n",
    "    path_steps = defaultdict(int)\n",
    "    for item in data:\n",
    "        path_steps[item[\"path_id\"]] += 1\n",
    "    return list(path_steps.values())\n",
    "\n",
    "def compute_nr_of_candidates(data):\n",
    "    nr_of_candidates = []\n",
    "    for item in data:\n",
    "        nr_of_candidates.append(len(item[\"candidates\"]))\n",
    "        \n",
    "    return nr_of_candidates\n",
    "        \n",
    "\n",
    "# Helper to compute instruction lengths\n",
    "def compute_instruction_lengths(data):\n",
    "    lengths = []\n",
    "    seen_path_ids = set()\n",
    "    for item in data:\n",
    "        if item[\"path_id\"] not in seen_path_ids:\n",
    "            seen_path_ids.add(item[\"path_id\"])\n",
    "            for inst in item[\"instructions\"]:\n",
    "                token_count = len(inst.split())\n",
    "                lengths.append(token_count)\n",
    "    return lengths\n",
    "\n",
    "# Gather data\n",
    "splits = {\n",
    "    \"Train\": train_data,\n",
    "}\n",
    "\n",
    "path_length_data = []\n",
    "instruction_length_data = []\n",
    "nr_of_candidates = []\n",
    "\n",
    "for split_name, data in splits.items():\n",
    "    # Path lengths\n",
    "    lengths = compute_path_lengths(data)\n",
    "    for length in lengths:\n",
    "        path_length_data.append({\"Split\": split_name, \"Steps per Path\": length})\n",
    "\n",
    "    # Instruction lengths\n",
    "    instr_lens = compute_instruction_lengths(data)\n",
    "    for instr_len in instr_lens:\n",
    "        instruction_length_data.append({\"Split\": split_name, \"Instruction Length\": instr_len})\n",
    "        \n",
    "    cand_lens = compute_nr_of_candidates(data)\n",
    "    \n",
    "    for can in cand_lens:\n",
    "        nr_of_candidates.append({\"Split\": split_name, \"Nr of Candidates\" : can})\n",
    "\n",
    "# Convert to DataFrames\n",
    "path_length_df = pd.DataFrame(path_length_data)\n",
    "instr_length_df = pd.DataFrame(instruction_length_data)\n",
    "can_df = pd.DataFrame(nr_of_candidates)\n",
    "\n",
    "can_mean = float(can_df.mean())\n",
    "can_median = float(can_df.median())\n",
    "\n",
    "\n",
    "# Plot: Histogram of steps per path\n",
    "plt.figure(figsize=(9, 5))\n",
    "sns.histplot(\n",
    "    data=can_df, \n",
    "    x=\"Nr of Candidates\", \n",
    "    bins=13, \n",
    "    multiple=\"dodge\", \n",
    "    color=sns.color_palette(\"colorblind\")[0], \n",
    "    edgecolor=\"black\",\n",
    "    alpha=1.0\n",
    ")\n",
    "# Add vertical lines\n",
    "plt.axvline(can_mean, color=palette[1], linestyle=\"--\", linewidth=1.5, label=f\"Mean: {can_mean:.1f}\")\n",
    "plt.axvline(can_median, color=palette[2], linestyle=\"--\", linewidth=1.5, label=f\"Median: {can_median:.1f}\")\n",
    "# Add legend to show labels\n",
    "plt.legend(fontsize=14)\n",
    "\n",
    "plt.xlabel(\"Number of Candidates\", fontsize=18)\n",
    "plt.ylabel(\"Count\", fontsize=18)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./figures/histogram_candidates_full.pdf\", bbox_inches=\"tight\", dpi=700)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12103b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map your splits to the original full R2R splits\n",
    "original_r2r_paths = {\n",
    "    \"Train\": len(set([item[\"path_id\"] for item in r2r_train])),\n",
    "    \"Val\": len(set([item[\"path_id\"] for item in r2r_seen])),\n",
    "    \"Test\": len(set([item[\"path_id\"] for item in r2r_unseen]))\n",
    "}\n",
    "\n",
    "def avg_steps_per_path(data):\n",
    "    path_lengths = {}\n",
    "    for item in data:\n",
    "        pid = item[\"path_id\"]\n",
    "        path_lengths[pid] = path_lengths.get(pid, 0) + 1\n",
    "    return round(sum(path_lengths.values()) / len(path_lengths), 2)\n",
    "\n",
    "\n",
    "# Function to compute stats\n",
    "def compute_stats(data):\n",
    "    num_samples = len(data)\n",
    "    num_paths = len(set([item[\"path_id\"] for item in data]))\n",
    "    unique_environments = len(set([item[\"scan\"] for item in data]))\n",
    "    avg_steps = avg_steps_per_path(data)\n",
    "    avg_nr_candidates = sum(compute_nr_of_candidates(data))/len(data)\n",
    "    \n",
    "    action_counts = Counter([\n",
    "        item[\"gold_label\"] for item in data\n",
    "    ])\n",
    "    return num_samples, num_paths, action_counts, unique_environments, avg_steps, avg_nr_candidates\n",
    "\n",
    "# Compute stats\n",
    "splits = {\n",
    "    \"Train\": train_data,\n",
    "    \"Val\": val_data,\n",
    "    \"Test\": test_data\n",
    "}\n",
    "\n",
    "summary_data = []\n",
    "plot_data = []\n",
    "total_action_counts = Counter()\n",
    "\n",
    "for split_name, data in splits.items():\n",
    "    num_samples, num_paths, action_counts, unique_environments, avg_steps, avg_nr_candidates = compute_stats(data)\n",
    "    summary_data.append({\n",
    "        \"Split\": split_name,\n",
    "        \"Num Samples\": num_samples,\n",
    "        \"Num Paths\": num_paths,\n",
    "        \"Unique Environments\" : unique_environments,\n",
    "        \"Avg Steps Per Path\" : avg_steps,\n",
    "        \"Avg Nr Candidates\" : round(avg_nr_candidates,2)\n",
    "    })\n",
    "    total = sum(action_counts.values())\n",
    "    total_action_counts.update(action_counts)\n",
    "\n",
    "    for action, count in action_counts.items():\n",
    "        plot_data.append({\n",
    "            \"Split\": split_name,\n",
    "            \"Action\": action,\n",
    "            \"Percentage\": (count / total) * 100\n",
    "        })\n",
    "\n",
    "# Order actions by total frequency\n",
    "ordered_actions = [action for action, _ in total_action_counts.most_common()]\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "plot_df[\"Action\"] = pd.Categorical(plot_df[\"Action\"], categories=ordered_actions, ordered=True)\n",
    "\n",
    "total_paths_used = sum(row[\"Num Paths\"] for row in summary_data)\n",
    "\n",
    "# Add relative path share (%) to each row\n",
    "for row in summary_data:\n",
    "    split_name = row[\"Split\"]\n",
    "    used_paths = row[\"Num Paths\"]\n",
    "    total_paths_in_r2r = original_r2r_paths[split_name]\n",
    "    row[\"Data Usage (%)\"] = round((used_paths / total_paths_in_r2r) * 100, 2)\n",
    "\n",
    "# Final tidy DataFrame\n",
    "summary_df = pd.DataFrame(summary_data)[[\n",
    "    \"Split\", \"Num Samples\", \"Num Paths\", \"Data Usage (%)\", \"Unique Environments\", \"Avg Steps Per Path\", \"Avg Nr Candidates\"\n",
    "]]\n",
    "\n",
    "# Print nicely\n",
    "print(\"=== Dataset Summary ===\")\n",
    "print(summary_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a69587f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
